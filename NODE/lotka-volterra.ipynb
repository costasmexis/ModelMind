{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torchdiffeq import odeint as odeint\n",
    "import pylab as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Callable, List, Tuple, Union, Optional\n",
    "from pathlib import Path  \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LotkaVolterra(nn.Module):\n",
    "    \"\"\" \n",
    "     The Lotka-Volterra equations are a pair of first-order, non-linear, differential equations\n",
    "     describing the dynamics of two species interacting in a predator-prey relationship.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 alpha: float = 3.0, # The alpha parameter of the Lotka-Volterra system\n",
    "                 beta: float =  0.6,  # The beta parameter of the Lotka-Volterra system\n",
    "                 gamma: float = 0.5, # The delta parameter of the Lotka-Volterra system\n",
    "                 delta: float = 4.0  # The gamma parameter of the Lotka-Volterra system\n",
    "                 ) -> None:\n",
    "        super().__init__()\n",
    "        self.model_params = torch.nn.Parameter(torch.tensor([alpha, beta, delta, gamma]))\n",
    "        \n",
    "        \n",
    "    def forward(self, t, state):\n",
    "        x = state[...,0]      #variables are part of vector array u \n",
    "        y = state[...,1]\n",
    "        sol = torch.zeros_like(state)\n",
    "        \n",
    "        #coefficients are part of tensor model_params\n",
    "        alpha, beta, delta, gamma = self.model_params    \n",
    "        sol[...,0] = alpha*x - beta*x*y\n",
    "        sol[...,1] = -delta*y + gamma*x*y\n",
    "        return sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lv_model = LotkaVolterra().to(device)\n",
    "ts = torch.arange(0.0, 4.0, .08, device=device)\n",
    "y0 = torch.tensor([10., 3.], device=device)\n",
    "y_true = odeint(lv_model, y0, ts, method='dopri5').detach()\n",
    "print(f'Dataset length: {y_true.shape[1]}')\n",
    "\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.scatter(ts.cpu().detach().numpy(), y_true[:,0].cpu().detach().numpy(), label='x', marker='.')\n",
    "plt.scatter(ts.cpu().detach().numpy(), y_true[:,1].cpu().detach().numpy(), label='y', marker='.')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Population')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LotkaVolterra(alpha=1.0, beta=1.5, gamma=0.8, delta=3.0).to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "# for epoch in range(100):\n",
    "#     optimizer.zero_grad()\n",
    "#     y_pred = odeint(model, y0, ts, method='dopri5')\n",
    "#     loss = criterion(y_pred, y_true)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     if epoch % 10 == 0:\n",
    "#         print(f'Epoch {epoch}, Loss {loss.item()}')\n",
    "\n",
    "# # Get model parameters values\n",
    "# alpha, beta, delta, gamma = model.model_params\n",
    "# print(f'alpha: {alpha:.2f}, beta: {beta:.2f}, delta: {delta:.2f}, gamma: {gamma:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralDiffeq(nn.Module):\n",
    "    \"\"\"\n",
    "        Basic Neural ODE model\n",
    "    \"\"\"\n",
    "    def __init__(self, dim: int = 2) -> None:\n",
    "        super().__init__()\n",
    "        self.func = nn.Sequential(\n",
    "            nn.Linear(dim, 8),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(8, 16),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, t, state):\n",
    "        return self.func(state)\n",
    "\n",
    "# Define the model, optimizer and loss function    \n",
    "model = NeuralDiffeq(dim=2).to(device)\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = []\n",
    "for epoch in range(2000):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = odeint(model, y0, ts, method='rk4')\n",
    "    loss = criterion(y_pred, y_true)\n",
    "    loss.backward()\n",
    "    total_loss.append(loss.item())  \n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 2))\n",
    "plt.plot(total_loss)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale('log')   \n",
    "plt.title('Training loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "y_pred = odeint(model, y0, ts, method='dopri5').detach()\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.scatter(ts.cpu().detach().numpy(), y_true[:,0].cpu().detach().numpy(), label='x', marker='.')\n",
    "plt.scatter(ts.cpu().detach().numpy(), y_true[:,1].cpu().detach().numpy(), label='y', marker='.')\n",
    "plt.plot(ts.cpu().detach().numpy(), y_pred[:,0].cpu().detach().numpy(), label='x_pred')\n",
    "plt.plot(ts.cpu().detach().numpy(), y_pred[:,1].cpu().detach().numpy(), label='y_pred')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Population')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
